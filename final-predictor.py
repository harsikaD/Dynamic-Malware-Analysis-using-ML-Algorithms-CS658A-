import pandas as pd
from sklearn.decomposition import PCA
from pandas import DataFrame
from sklearn.model_selection import StratifiedKFold
from sklearn.svm import SVC
from sklearn import preprocessing
import matplotlib.pyplot as plt
import joblib
import json
import pickle as pk

dataFile=pd.read_csv("final-data.csv");
features=list(dataFile.columns);

def extractData(json_data):
    lst=[];
    tempDict={};
    tempList=[];
    apiDict={};
    apiKeys=0;
    if "behavior" in json_data.keys():
        if "generic" in json_data["behavior"].keys():
            for i in json_data["behavior"]["generic"]:
                if "summary" in i.keys():
                    if "dll_loaded" in i["summary"].keys():
                        tempList.append(i["summary"]["dll_loaded"])
                    if "file_written" in i["summary"].keys():
                        tempList.append(i["summary"]["file_written"])
                    if "regkey_written" in i["summary"].keys():
                        tempList.append(i["summary"]["regkey_written"])
                    if "regkey_deleted" in i["summary"].keys():
                        tempList.append(i["summary"]["regkey_deleted"])
                    if "file_deleted" in i["summary"].keys():
                        tempList.append(i["summary"]["file_deleted"])

            
        if "apistats" in json_data["behavior"].keys():
            for i in json_data["behavior"]["apistats"].keys():
                apiKeys=i;

            apiDict=(json_data["behavior"]["apistats"][apiKeys]);
    
    tempList.append(apiDict);
    #tempList.append(fileClass);

    return tempList;

f = open("report.json");
inputData = json.load(f);
duration=inputData["info"]["duration"];
#score=inputData["info"]["score"];
finalFeatures=extractData(inputData);

tempDataDict={};
for tempFeat in features:
    tempDataDict[tempFeat]=0;

for i in features:
    idx=0;
    while idx<len(finalFeatures)-1:
        if i in finalFeatures[idx]:#for feat in ele[idx]:
            tempDataDict[i]=1;
        
        idx+=1;

    if i in finalFeatures[len(finalFeatures)-1].keys():
        #if k in features:
        tempDataDict[i]=finalFeatures[len(finalFeatures)-1][i];

tempDataDict["duration"]=duration;
#tempDataDict["score"]=score;
tempDataDict["label"]="none";

valuedList=[];
for feat in features:
    valuedList.append(tempDataDict[feat]);

#valuedList.append(duration)#(ele[len(ele)-2]);
#valuedList.append(score)#(ele[len(ele)-1]);
#valuedList.append("none")#(ele[len(ele)-3]);
#print(features)

data=pd.DataFrame([valuedList],columns=features);
print(data)
"""Taking Data except labels"""


data_x = data.iloc[:,0:14818];
#print(list(data_x.iloc[0]))
#print("-------------------")
print(type(data_x))
"""Normalizing Data"""

#data_normalized=(data_x - data_x.mean()) / data_x.std()
#print(type(data_normalized))

# later reload the pickle file
pca_reload = pk.load(open("pca.pkl",'rb'))
result_new = pca_reload.transform(data_x)
#pca.fit(data_x)

# pca.components_

"""Top 500 features of PCA"""

columns = ['pca_%i' % i for i in range(500)]
df_pca = DataFrame(result_new, columns=columns)

X = df_pca.iloc[:,0:500]
#y = df_pca[df_pca.columns[-1]]

# #Converting categorical attribute "label" to numerical using label encoder


# from sklearn.preprocessing import OneHotEncoder

# #creating instance of one-hot-encoder
# encoder = OneHotEncoder(handle_unknown='ignore')

# #perform one-hot encoding on 'team' column 
# y = pd.DataFrame(encoder.fit_transform(df_pca[["label"]]).toarray())

#scaler = preprocessing.MinMaxScaler()
#x_scaled = scaler.fit_transform(X)


dnn = joblib.load('dnn.pkl')

labelOrder=['Backdore', 'Benign', 'Trojan-Downloader', 'Trojan-Dropper','Trojan', 'Virus', 'Worm'];

pred=dnn.predict(X)[0];

#print((pred));

print("Prediction: ",labelOrder[pred.argmax(axis=0)]);


